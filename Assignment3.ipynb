{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xQa6VlNAOe"
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0mG3n0qRNTSA",
    "outputId": "cb0eadbd-b8a8-41b1-e3b4-7f44b47a8804",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load MovieLens 100K dataset into a dataframe of pandas\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFJT0QWudp1P"
   },
   "outputs": [],
   "source": [
    "# Select 500 most active users and 500 most active items from the dataset\n",
    "n_most_active_users = 500\n",
    "n_most_active_items = 500\n",
    "\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(n_most_active_users).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(n_most_active_items).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r012fu0jJkJc"
   },
   "outputs": [],
   "source": [
    "# Map new internal ID for items\n",
    "i_ids = df['item_id'].unique().tolist()\n",
    "item_dict = dict(zip(i_ids, [i for i in range(len(i_ids))]))\n",
    "df['item_id'] = df['item_id'].map(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ3rlC7jO6WJ"
   },
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwS00lvHO-ca",
    "outputId": "f9f3a031-b4e7-439e-c3e3-c165b2286d19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fb140fbf3b12>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
      "<ipython-input-4-fb140fbf3b12>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n"
     ]
    }
   ],
   "source": [
    "# The number of training users and active users\n",
    "n_training_users = 300\n",
    "n_active_users = n_most_active_users - n_training_users\n",
    "\n",
    "# The number of GIVEN ratings for active users\n",
    "GIVEN = 20\n",
    "\n",
    "# Randomly select users from the most active users as training set\n",
    "random_uids = np.random.choice(df.user_id.unique(), n_training_users, replace=False)\n",
    "train_df = df[df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all users in the training set\n",
    "u_ids = train_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
    "\n",
    "# The rest of users are active users for testing\n",
    "remain_df = df[~df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all active users\n",
    "u_ids = remain_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n",
    "\n",
    "# Randomly select GIVEN ratings for active users\n",
    "active_df = remain_df.groupby('user_id').sample(n=GIVEN, random_state=1024)\n",
    "\n",
    "test_df = remain_df[~remain_df.index.isin(active_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-ke62G3jiYb",
    "outputId": "1c135984-edb4-4f2b-fc73-9225d86a0c38",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  2.0  0.0  4.0  0.0  4.0  4.0  0.0  0.0  2.0  ...  0.0  4.0  4.0   \n",
       " 1        0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        4.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        4.0  0.0  5.0  0.0  1.0  0.0  3.0  2.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  5.0  5.0  0.0  3.0  5.0  0.0  ...  0.0  4.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 295      0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  4.0  5.0  ...  0.0  0.0  4.0   \n",
       " 296      0.0  0.0  5.0  4.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       " 297      0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 298      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  4.0  0.0   \n",
       " 299      0.0  0.0  0.0  3.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  5.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  3.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        4.0  1.0  0.0  0.0  0.0  0.0  2.0  \n",
       " 4        0.0  0.0  0.0  3.0  0.0  3.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 295      0.0  4.0  2.0  3.0  0.0  0.0  0.0  \n",
       " 296      0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       " 297      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 298      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 299      0.0  0.0  3.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [300 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        4.0  0.0  0.0  0.0  0.0  3.0  4.0  2.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  5.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  ...  0.0  2.0  0.0   \n",
       " 3        3.0  0.0  4.0  0.0  0.0  3.0  0.0  2.0  0.0  0.0  ...  0.0  4.0  0.0   \n",
       " 4        0.0  0.0  0.0  5.0  4.0  4.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  4.0  0.0  5.0  0.0  4.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  4.0   \n",
       " 198      4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  ...  4.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  4.0  0.0  3.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  4.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  2.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      5.0  0.0  0.0  3.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the format of datasets to matrices\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_training_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_training_users), 'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_active_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_active_users), 'rating': 0})\n",
    "active_ds = df_zeros.merge(active_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "test_ds = df_zeros.merge(test_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "train_ds, active_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yElYv2TDKKGu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting All Missing Data in training set\n",
    "imputed_train_ds = train_ds.values.copy()\n",
    "imputed_train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy4FurbHD4dt"
   },
   "source": [
    "# Implementation to predict the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zYh1bVd0ncz3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## The following parameters are required in the given report\n",
    "LAMBDA = 0.7    # λ\n",
    "GAMMA = 10      # γ\n",
    "DELTA = 10      # δ\n",
    "ITA = 0.7       # η\n",
    "THETA = 0.7     # θ\n",
    "EPSILON = 1e-9\n",
    "\n",
    "## Get the size of user-item matrix\n",
    "n_users = imputed_train_ds.shape[0]\n",
    "n_items = imputed_train_ds.shape[1]\n",
    "\n",
    "\n",
    "## Compute User-based Pearson Correlation Coefficient\n",
    "\n",
    "# Create the user-user matrix\n",
    "user_pearson_corr = np.zeros((n_users, n_users))\n",
    "\n",
    "# Loop to calculate similarity for each pair of users\n",
    "for i, user_i_vec in enumerate(imputed_train_ds):\n",
    "    for j, user_j_vec in enumerate(imputed_train_ds):\n",
    "        \n",
    "        # In case of the user versus themselves, the similarity is 1\n",
    "        if i == j:\n",
    "            user_pearson_corr[i][j] = 0\n",
    "            \n",
    "        # In case the similarity is already computed, simply assign its value to the cell\n",
    "        elif j < i:\n",
    "            user_pearson_corr[i][j] = user_pearson_corr[j][i]\n",
    "            \n",
    "        # Otherwise, calculate the similarity\n",
    "        else:\n",
    "            # Find a list of indices that two users both rated\n",
    "            user_i_rated_indices = np.array(user_i_vec) > 0\n",
    "            user_j_rated_indices = np.array(user_j_vec) > 0\n",
    "            corrated_items_index = np.intersect1d(np.where(user_i_rated_indices), np.where(user_j_rated_indices))\n",
    "            \n",
    "            length = len(corrated_items_index)\n",
    "            \n",
    "            if length == 0:\n",
    "                user_pearson_corr[i][j] = 0\n",
    "            else:   \n",
    "                # Extract an array of ratings from two users for corrated items\n",
    "                corrated_items_user_i_rated = user_i_vec[corrated_items_index]\n",
    "                corrated_items_user_j_rated = user_j_vec[corrated_items_index]\n",
    "                \n",
    "                # Calculate average rating for two users\n",
    "                user_i_avg_rating = sum(corrated_items_user_i_rated) / length\n",
    "                user_j_avg_rating = sum(corrated_items_user_j_rated) / length\n",
    "\n",
    "                # Calculate the subtraction of ratings and average rating for two users\n",
    "                user_i_rating_sub = corrated_items_user_i_rated - user_i_avg_rating\n",
    "                user_j_rating_sub = corrated_items_user_j_rated - user_j_avg_rating\n",
    "\n",
    "                # Calculate the covariance\n",
    "                covariance = sum(user_i_rating_sub*user_j_rating_sub)\n",
    "\n",
    "                # Calculate the sum of square for rating subtraction for two users\n",
    "                user_i_sq_sum = sum(np.square(user_i_rating_sub))\n",
    "                user_j_sq_sum = sum(np.square(user_j_rating_sub))\n",
    "\n",
    "                # Calculate the standard deviation for two users\n",
    "                user_i_sqrt = np.sqrt(user_i_sq_sum)\n",
    "                user_j_sqrt = np.sqrt(user_j_sq_sum)\n",
    "                \n",
    "                user_std = EPSILON\n",
    "                \n",
    "                if user_i_sqrt != 0 and user_j_sqrt != 0:\n",
    "                    user_std = user_i_sqrt * user_j_sqrt\n",
    "\n",
    "                # Calculate the similarity\n",
    "                sim = covariance / user_std\n",
    "\n",
    "                # Re-calculate with the correlation significance weighting factor\n",
    "                weighted_sim = (min(len(corrated_items_index), GAMMA)/GAMMA) * sim\n",
    "\n",
    "                # Assign value in the user-user matrix\n",
    "                user_pearson_corr[i][j] = weighted_sim\n",
    "                \n",
    "                \n",
    "## Compute Item-based Pearson Correlation Coefficient\n",
    "\n",
    "# Create the item-item matrix\n",
    "item_pearson_corr = np.zeros((n_items, n_items))\n",
    "\n",
    "# Loop to calculate similarity for each pair of items\n",
    "for i, item_i_vec in enumerate(imputed_train_ds.T):\n",
    "    for j, item_j_vec in enumerate(imputed_train_ds.T):\n",
    "        \n",
    "        # In case of the item versus itself, the similarity is 1\n",
    "        if i == j:\n",
    "            item_pearson_corr[i][j] = 0\n",
    "            \n",
    "        # In case the similarity is already computed, simply assign its value to the cell\n",
    "        elif j < i:\n",
    "            item_pearson_corr[i][j] = item_pearson_corr[j][i]\n",
    "\n",
    "        # Otherwise, calculate the similarity\n",
    "        else:\n",
    "            # Find a list of indices that two items were both rated\n",
    "            item_i_rated_indices = np.array(item_i_vec) > 0\n",
    "            item_j_rated_indices = np.array(item_j_vec) > 0\n",
    "            corrated_users_index = np.intersect1d(np.where(item_i_rated_indices), np.where(item_j_rated_indices))\n",
    "            \n",
    "            length = len(corrated_users_index)\n",
    "            \n",
    "            if length == 0:\n",
    "                item_pearson_corr[i][j] = 0\n",
    "            else:\n",
    "                # Extract an array of ratings for two items by corrated users\n",
    "                item_i_rating_by_corrated_users = item_i_vec[corrated_users_index]\n",
    "                item_j_rating_by_corrated_users = item_j_vec[corrated_users_index]\n",
    "                \n",
    "                # Calculate average rating for two items\n",
    "                item_i_avg_rating = sum(item_i_rating_by_corrated_users) / length\n",
    "                item_j_avg_rating = sum(item_j_rating_by_corrated_users) / length\n",
    "\n",
    "                # Calculate the subtraction of ratings and average rating for two items\n",
    "                item_i_rating_sub = item_i_rating_by_corrated_users - item_i_avg_rating\n",
    "                item_j_rating_sub = item_j_rating_by_corrated_users - item_j_avg_rating\n",
    "\n",
    "                # Calculate the covariance\n",
    "                covariance = sum(item_i_rating_sub*item_j_rating_sub)\n",
    "\n",
    "                # Calculate the sum of square for rating subtraction for two items\n",
    "                item_i_sq_sum = sum(np.square(item_i_rating_sub))\n",
    "                item_j_sq_sum = sum(np.square(item_j_rating_sub))\n",
    "\n",
    "                # Calculate the standard deviation for two items\n",
    "                item_i_sqrt = np.sqrt(item_i_sq_sum)\n",
    "                item_j_sqrt = np.sqrt(item_j_sq_sum)\n",
    "                \n",
    "                item_std = EPSILON\n",
    "                if item_i_sqrt != 0 and item_j_sqrt != 0:\n",
    "                    item_std = item_i_sqrt * item_j_sqrt\n",
    "\n",
    "                # Calculate the similarity\n",
    "                sim = covariance / item_std\n",
    "\n",
    "                # Re-calculate with the correlation significance weighting factor\n",
    "                weighted_sim = (min(len(corrated_users_index), DELTA)/DELTA) * sim\n",
    "                \n",
    "                # Assign value in the item-item matrix\n",
    "                item_pearson_corr[i][j] = weighted_sim\n",
    "            \n",
    "            \n",
    "## Prediction of missing values\n",
    "\n",
    "np_predictions = imputed_train_ds.copy()\n",
    "\n",
    "# Loop to predict ratings in user-item matrix\n",
    "for (i, j), rating in np.ndenumerate(imputed_train_ds):\n",
    "    \n",
    "    # If a rating data is missing, predict its value\n",
    "    if rating == 0:\n",
    "        # Initialize prediction value\n",
    "        pred_value = 0\n",
    "        \n",
    "        # Calculate set of similar users for user i\n",
    "        mask_sim_users = user_pearson_corr[i] > ITA\n",
    "        users_indices = [index for index, x in enumerate(mask_sim_users) if x]\n",
    "        \n",
    "        # Remove the user from set of similar users if that user did not rate item j\n",
    "        sim_users_indices = []\n",
    "        for index in users_indices:\n",
    "            if imputed_train_ds[index][j] > 0:\n",
    "                sim_users_indices.append(index)\n",
    "\n",
    "        sim_users = user_pearson_corr[i][sim_users_indices]\n",
    "        sim_users_count = len(sim_users)\n",
    "        \n",
    "        # Calculate set of similar items for item j\n",
    "        mask_sim_items = item_pearson_corr[j] > THETA\n",
    "        items_indices = [index for index, x in enumerate(mask_sim_items) if x]\n",
    "        \n",
    "        # Remove the item from set of similar items if that item was not rated by user i\n",
    "        sim_items_indices = []\n",
    "        for index in items_indices:\n",
    "            if imputed_train_ds[i][index] > 0:\n",
    "                sim_items_indices.append(index)\n",
    "                \n",
    "        sim_items = item_pearson_corr[j][sim_items_indices]\n",
    "        sim_items_count = len(sim_items)\n",
    "        \n",
    "        # Case 1: Both S(u) and S(j) are not empty\n",
    "        if sim_users_count != 0 and sim_items_count != 0:\n",
    "            \n",
    "            # Calculate average rating for current user and item\n",
    "            avg_rating_i = sum(imputed_train_ds[i])/sum(np.clip(imputed_train_ds[i], 0, 1))\n",
    "            avg_rating_j = sum(imputed_train_ds.T[j])/sum(np.clip(imputed_train_ds.T[j], 0, 1))\n",
    "            \n",
    "            # Extract a rating list of user i for set of similar items and item j for set of similar \n",
    "            rating_item_j_sim_users = imputed_train_ds.T[j][sim_users_indices]\n",
    "            rating_user_i_sim_items = imputed_train_ds[i][sim_items_indices]\n",
    "            \n",
    "            # Get the list of items that user i rated and list of users rated item j\n",
    "            user_i_rated_indices = imputed_train_ds[i] > 0\n",
    "            item_j_rated_indices = imputed_train_ds.T[j] > 0\n",
    "            \n",
    "            # Calculate average rating for each user in set of similar users and for each item in set of similar items\n",
    "            avg_rating_sim_users = []\n",
    "            for index, element in enumerate(imputed_train_ds):\n",
    "                if index in sim_users_indices:\n",
    "                    user_index_rated_indices = element > 0\n",
    "                    corrated_items = np.intersect1d(np.where(user_i_rated_indices), np.where(user_index_rated_indices))\n",
    "                    avg_rating_user = sum(element[corrated_items]) / len(corrated_items)\n",
    "                    avg_rating_sim_users.append(avg_rating_user)\n",
    "                    \n",
    "            avg_rating_sim_items = []\n",
    "            for index, element in enumerate(imputed_train_ds.T):\n",
    "                if index in sim_items_indices:\n",
    "                    item_index_rated_indices = element > 0\n",
    "                    corrated_users = np.intersect1d(np.where(item_j_rated_indices), np.where(item_index_rated_indices))\n",
    "                    avg_rating_item = sum(element[corrated_users]) / len(corrated_users)\n",
    "                    avg_rating_sim_items.append(avg_rating_item)\n",
    "                    \n",
    "            # Calculate subtraction of rating and average rating\n",
    "            rating_sub_avg_sim_users = rating_item_j_sim_users - avg_rating_sim_users\n",
    "            rating_sub_avg_sim_items = rating_user_i_sim_items - avg_rating_sim_items\n",
    "            \n",
    "            # Calculate the sum of sim multiply by sub\n",
    "            sum_sim_multiply_sub_user = sum(sim_users*rating_sub_avg_sim_users)\n",
    "            sum_sim_multiply_sub_item = sum(sim_items*rating_sub_avg_sim_items)\n",
    "            \n",
    "            # Calculate prediction value for item and user\n",
    "            pred_user = avg_rating_i + sum_sim_multiply_sub_user / sum(sim_users)\n",
    "            pred_item = avg_rating_j + sum_sim_multiply_sub_item / sum(sim_items)\n",
    "            \n",
    "            # Calculate the prediction value\n",
    "            pred_value = LAMBDA * pred_user + (1 - LAMBDA) * pred_item\n",
    "            \n",
    "        # Case 2: S(u) not empty and S(j) empty\n",
    "        elif sim_users_count != 0 and sim_items_count == 0:\n",
    "            \n",
    "            # Calculate average rating for the current user\n",
    "            avg_rating_i = sum(imputed_train_ds[i])/sum(np.clip(imputed_train_ds[i], 0, 1))\n",
    "            \n",
    "            # Get the list of items that user i rated\n",
    "            user_i_rated_indices = imputed_train_ds[i] > 0\n",
    "            \n",
    "            # Calculate average rating for each user in set of similar users\n",
    "            avg_rating_sim_users = []\n",
    "            for index, element in enumerate(imputed_train_ds):\n",
    "                if index in sim_users_indices:\n",
    "                    user_index_rated_indices = element > 0\n",
    "                    corrated_items = np.intersect1d(np.where(user_i_rated_indices), np.where(user_index_rated_indices))\n",
    "                    avg_rating_user = sum(element[corrated_items])/len(corrated_items)\n",
    "                    avg_rating_sim_users.append(avg_rating_user)\n",
    "                    \n",
    "            # Extract a rating list of item j for set of similar users\n",
    "            rating_item_j_sim_users = imputed_train_ds.T[j][sim_users_indices]\n",
    "            \n",
    "            # Calculate subtraction of rating and average rating\n",
    "            rating_sub_avg_sim_users = rating_item_j_sim_users - avg_rating_sim_users\n",
    "            \n",
    "            # Calculate the sum of sim multiply by sub\n",
    "            sum_sim_multiply_sub_user = sum(sim_users*rating_sub_avg_sim_users)\n",
    "            \n",
    "            # Calculate the prediction value\n",
    "            pred_value = avg_rating_i + sum_sim_multiply_sub_user/sum(sim_users)\n",
    "            \n",
    "        # Case 3: S(u) empty and S(j) not empty\n",
    "        elif sim_users_count == 0 and sim_items_count != 0:\n",
    "            \n",
    "            # Calculate average rating for the current item\n",
    "            avg_rating_j = sum(imputed_train_ds.T[j])/sum(np.clip(imputed_train_ds.T[j], 0, 1))\n",
    "            \n",
    "            # Get the list of users rated item j\n",
    "            item_j_rated_indices = imputed_train_ds.T[j] > 0\n",
    "            \n",
    "            # Calculate average rating for each item in set of similar items\n",
    "            avg_rating_sim_items = []\n",
    "            for index, element in enumerate(imputed_train_ds.T):\n",
    "                if index in sim_items_indices:\n",
    "                    item_index_rated_indices = element > 0\n",
    "                    corrated_users = np.intersect1d(np.where(item_j_rated_indices), np.where(item_index_rated_indices))\n",
    "                    avg_rating_item = sum(element[corrated_users])/len(corrated_users)\n",
    "                    avg_rating_sim_items.append(avg_rating_item)\n",
    "                    \n",
    "            # Extract a rating list of user i for set of similar items\n",
    "            rating_user_i_sim_items = imputed_train_ds[i][sim_items_indices]\n",
    "            \n",
    "            # Calculate subtraction of rating and average rating\n",
    "            rating_sub_avg_sim_items = rating_user_i_sim_items - avg_rating_sim_items\n",
    "            \n",
    "            # Calculate the sum of sim multiply by sub\n",
    "            sum_sim_multiply_sub_item = sum(sim_items*rating_sub_avg_sim_items)\n",
    "            \n",
    "            # Calculate the prediction value\n",
    "            pred_value = avg_rating_j + sum_sim_multiply_sub_item/sum(sim_items)\n",
    "            \n",
    "        # Case 4: Both S(u) and S(j) are empty, do nothing as prediction value is already initialized to 0\n",
    "        \n",
    "        # Assign prediction value to the according cell\n",
    "        np_predictions[i][j] = pred_value\n",
    "        np_predictions[i][j] = np.clip(np_predictions[i][j],0,5)\n",
    "        \n",
    "imputed_train_ds = np_predictions.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbOfVWTV_Aij"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txs8YjwTzuSP"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient of All Pairs of Items between active set and imputed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "KoOgX_axKKGw",
    "outputId": "37a7adbd-e0d6-4375-e28c-3940977896f2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.425074</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.402373</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.351020</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.645597</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.483082</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.907920</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.351318</td>\n",
       "      <td>1.496572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.474811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.689655</td>\n",
       "      <td>2.990424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>3.554829</td>\n",
       "      <td>3.079832</td>\n",
       "      <td>3.282890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.872283</td>\n",
       "      <td>4.256618</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.986031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.498245</td>\n",
       "      <td>...</td>\n",
       "      <td>1.729128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.778645</td>\n",
       "      <td>3.990424</td>\n",
       "      <td>2.751974</td>\n",
       "      <td>1.663048</td>\n",
       "      <td>4.373419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.507190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.067479</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.261941</td>\n",
       "      <td>3.128846</td>\n",
       "      <td>4.241216</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>4.296300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.753006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.243736</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.034025</td>\n",
       "      <td>3.403172</td>\n",
       "      <td>4.541226</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.811735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.601449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393126</td>\n",
       "      <td>4.067479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.053308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.257939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>3.104861</td>\n",
       "      <td>1.434783</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.182234</td>\n",
       "      <td>2.305640</td>\n",
       "      <td>0.806383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.764476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.182234</td>\n",
       "      <td>2.294313</td>\n",
       "      <td>0.541226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.933278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.617279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.628358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.628358</td>\n",
       "      <td>4.098765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.628358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.654323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.522989</td>\n",
       "      <td>4.055631</td>\n",
       "      <td>2.628358</td>\n",
       "      <td>3.057699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.806232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.522727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.522727</td>\n",
       "      <td>0.806383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.948716</td>\n",
       "      <td>2.522989</td>\n",
       "      <td>2.990424</td>\n",
       "      <td>2.369048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.757143</td>\n",
       "      <td>3.404626</td>\n",
       "      <td>3.234472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4.373016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.373016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.965504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.180063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.867532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.841759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2    3         4         5         6    \\\n",
       "0    4.425074  2.000000  3.402373  4.0  4.351020  4.000000  4.000000   \n",
       "1    5.000000  0.000000  4.000000  4.0  4.000000  0.000000  0.000000   \n",
       "2    4.000000  3.872283  4.256618  2.0  0.000000  2.986031  0.000000   \n",
       "3    4.000000  0.000000  5.000000  0.0  1.000000  1.067479  3.000000   \n",
       "4    5.000000  3.753006  0.000000  0.0  5.000000  5.000000  0.000000   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  0.000000  4.601449  0.000000  0.0  4.393126  4.067479  0.000000   \n",
       "296  3.104861  1.434783  5.000000  4.0  0.000000  1.000000  3.182234   \n",
       "297  5.000000  3.628358  0.000000  5.0  0.000000  4.628358  4.098765   \n",
       "298  2.522727  1.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "299  4.373016  0.000000  0.000000  3.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "          7         8         9    ...       490       491       492  \\\n",
       "0    0.000000  0.000000  2.000000  ...  2.645597  4.000000  4.000000   \n",
       "1    4.000000  0.000000  0.000000  ...  3.474811  0.000000  0.000000   \n",
       "2    0.000000  0.000000  3.498245  ...  1.729128  0.000000  0.000000   \n",
       "3    2.000000  0.000000  0.000000  ...  2.261941  3.128846  4.241216   \n",
       "4    3.000000  5.000000  0.000000  ...  3.243736  4.000000  4.034025   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  5.000000  4.000000  5.000000  ...  2.053308  0.000000  4.000000   \n",
       "296  2.305640  0.806383  1.000000  ...  2.764476  0.000000  2.182234   \n",
       "297  0.000000  1.628358  0.000000  ...  3.654323  0.000000  5.000000   \n",
       "298  2.522727  0.806383  0.000000  ...  3.000000  4.000000  2.948716   \n",
       "299  4.000000  0.000000  3.373016  ...  1.965504  0.000000  5.000000   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    3.483082  3.000000  3.000000  2.907920  5.000000  2.351318  1.496572  \n",
       "1    4.689655  2.990424  0.000000  4.033333  3.554829  3.079832  3.282890  \n",
       "2    4.778645  3.990424  2.751974  1.663048  4.373419  0.000000  2.507190  \n",
       "3    4.000000  1.000000  0.000000  3.033333  4.296300  0.000000  2.000000  \n",
       "4    3.403172  4.541226  0.250000  3.000000  5.000000  3.000000  2.811735  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295  5.000000  4.000000  2.000000  3.000000  5.000000  0.000000  3.257939  \n",
       "296  2.294313  0.541226  0.000000  0.000000  2.933278  1.000000  2.617279  \n",
       "297  3.522989  4.055631  2.628358  3.057699  0.000000  0.000000  3.806232  \n",
       "298  2.522989  2.990424  2.369048  0.000000  3.757143  3.404626  3.234472  \n",
       "299  4.180063  0.000000  3.000000  0.000000  4.867532  0.000000  2.841759  \n",
       "\n",
       "[300 rows x 500 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_train_ds = pd.DataFrame(imputed_train_ds)\n",
    "imputed_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq0uq1aHzu11",
    "outputId": "f6214a46-d63e-4fdc-e7dd-ccaed23b237d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06834807, -0.11825281, -0.3618097 , ...,  0.05649737,\n",
       "        -0.21006067,  0.55411922],\n",
       "       [ 0.02085776, -0.35505123,  0.45130864, ..., -0.15909952,\n",
       "         0.29091363,  0.07351821],\n",
       "       [-0.05241235,  0.21306032,  0.19074118, ..., -0.07058337,\n",
       "         0.17362642, -0.22867732],\n",
       "       ...,\n",
       "       [ 0.3885444 ,  0.6166051 ,  0.06399615, ...,  0.54401705,\n",
       "        -0.2083534 ,  0.58643886],\n",
       "       [ 0.22896284,  0.48473701,  0.0974579 , ...,  0.57082826,\n",
       "         0.65231431,  0.03444186],\n",
       "       [ 0.23649629, -0.23892767, -0.06896578, ..., -0.14897401,\n",
       "         0.10426395,  0.05929731]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_user_pearson_corr = np.zeros((active_ds.shape[0], train_ds.shape[0]))\n",
    "\n",
    "# Compute Pearson Correlation Coefficient of All Pairs of Users between active set and imputed training set\n",
    "for i, user_i_vec in enumerate(active_ds.values):\n",
    "    for j, user_j_vec in enumerate(imputed_train_ds.values):\n",
    "        \n",
    "        # ratings corated by the current pair od users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        active_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "active_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewTnN9kNb8Ys"
   },
   "source": [
    "## Predict Ratings of Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ERndYXb8Ys",
    "outputId": "12607670-af61-403a-e4ce-f5e874bf8386",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 2.36458673,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 3.85921733, ..., 3.38491988, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [4.24176149, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "\n",
    "test_ds_pred = np.zeros_like(test_ds.values)\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "\n",
    "    if rating > 0:\n",
    "\n",
    "        sim_user_ids = np.argsort(active_user_pearson_corr[i])[-1:-(K + 1):-1]\n",
    "\n",
    "        #==================user-based==================#\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = active_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = imputed_train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "        test_ds_pred[i][j] = user_based_pred\n",
    "        \n",
    "test_ds_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUTn4kSFb8ZA"
   },
   "source": [
    "## Compute MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JCVmexyb8ZA",
    "outputId": "6f650170-e9a6-482a-b695-5fa474d964b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7706912964162808, RMSE: 0.9890086344496307\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "MAE = np.sum(np.abs(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1))\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(np.square(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1)))\n",
    "\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment3_framework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
